import pandas as pd
import json
from confluent_kafka import Producer
import time

# Config Kafka optimisÃ©e BIG DATA
conf = {
    'bootstrap.servers': 'localhost:9092',
    'linger.ms': 100,      
    'batch.size': 16384,   
    'compression.type': 'snappy'
}

# VÃ©rif dataset
csv_path = "D:/medallion_ecommerce/data/ecommerce_transactions.csv"
print(" Chargement des donnees ")
df = pd.read_csv(csv_path)

print(f" {len(df):,} transactions | Colonnes: {list(df.columns)}")
print(df.head(2))

# Kafka producer optimisÃ©
p = Producer(conf)

def delivery(err, msg):
    if err:
        print(f" ERREUR: {err}")
    else:
        global count
        count += 1
        if count % 1000 == 0:
            print(f"ðŸ“¡ {count:,}/{total} â†’ Kafka BRONZE")

total = len(df)
count = 0

print(f" STREAMING COMPLET {total:,} transactions vers Kafka.")

for i, row in df.iterrows(): 
    record = row.to_dict()
    record['_bronze_ts'] = time.time()
    p.produce('raw_transactions', key=str(i), value=json.dumps(record), callback=delivery)


p.flush()
print(f" {total:,} transactions â†’ Kafka BRONZE COMPLET !")
print(f" Temps: {time.time() - start_time:.1f}s")

